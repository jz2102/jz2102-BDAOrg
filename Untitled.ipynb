{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cells': [{'cell_type': 'markdown',\n",
       "   'metadata': {},\n",
       "   'source': ['# Assignment 02\\n',\n",
       "    '\\n',\n",
       "    '**Due:** Thursday, 2020-02-13, 11:59 PM, as a Jupyter notebook submitted via your repo in the course GitHub organization (see the detailed submission instructions in our LabResources repo).  Edit the provided Solution02 notebook with your solutions.  All subproblems are worth 1 point unless otherwise noted (grading will assign fractional points as appropriate).']},\n",
       "  {'cell_type': 'markdown',\n",
       "   'metadata': {},\n",
       "   'source': ['## 1. Logic problems\\n',\n",
       "    '\\n',\n",
       "    \"We will not be using propositional logic extensively in this course, but it's important to grasp basic logic in order to understand the goals and interpretation of Bayesian inference.\\n\",\n",
       "    '\\n',\n",
       "    'In class we discussed three fundamental logical operations, the unary (operating on a single proposition) **NOT** (denial) operation, and the binary (operating on two propositions) **AND** (conjuction) and **OR** (disjunction) operations.  For propositions $A$ and $B$, with 0 denoting *False* and 1 denoting *True*, the following truth tables describe these operations (I\\'ve separated inputs from outputs with an empty column; note that the notebook\\'s table renderer may split headers like \"$A\\\\land B$\", etc., across a line):\\n',\n",
       "    '\\n',\n",
       "    '| $A$ |   | $\\\\overline{A}$ |\\n',\n",
       "    '|-----|:-:|----------------|\\n',\n",
       "    '| 0   |   | 1              |\\n',\n",
       "    '| 1   |   | 0              |\\n',\n",
       "    '\\n',\n",
       "    '| $A$ | $B$ |   | $A \\\\land B$ | $A \\\\lor B$ |\\n',\n",
       "    '|:---:|:---:|---|:-----------:|:----------:|\\n',\n",
       "    '| 0   | 0   |   | 0           | 0          |\\n',\n",
       "    '| 0   | 1   |   | 0           | 1          |\\n',\n",
       "    '| 1   | 0   |   | 0           | 1          |\\n',\n",
       "    '| 1   | 1   |   | 1           | 1          |\\n',\n",
       "    '\\n',\n",
       "    'Of course, there are other useful truth-functional operations (unary, binary, and higher order).  For example, **OR** is defined to correspond to *inclusive* \"or\" in English, but we could also define an *exclusive* \"or\" operation (\"either $A$ or $B$, but not both\"), denoted by $\\\\veebar$ and called **XOR**, according to the following truth table:\\n',\n",
       "    '\\n',\n",
       "    '| $A$ | $B$ |   | $A \\\\veebar B$ |\\n',\n",
       "    '|:---:|:---:|---|:-------------:|\\n',\n",
       "    '| 0   | 0   |   | 0             |\\n',\n",
       "    '| 0   | 1   |   | 1             |\\n',\n",
       "    '| 1   | 0   |   | 1             |\\n',\n",
       "    '| 1   | 1   |   | 0             |\\n',\n",
       "    '\\n',\n",
       "    'Similarly, propositional logic uses a *material implication* operator, denoted by $\\\\Rightarrow$, to capture the weakest meaning of statements like \"if $A$ is true, then $B$ must be,\" with this truth table:\\n',\n",
       "    '\\n',\n",
       "    '| $A$ | $B$ |   | $A \\\\Rightarrow B$ |\\n',\n",
       "    '|:---:|:---:|---|:-----------------:|\\n',\n",
       "    '| 0   | 0   |   | 1                 |\\n',\n",
       "    '| 0   | 1   |   | 1                 |\\n',\n",
       "    '| 1   | 0   |   | 0                 |\\n',\n",
       "    '| 1   | 1   |   | 1                 |\\n',\n",
       "    '\\n',\n",
       "    '$A \\\\Rightarrow B$ captures a weak interpretation of \"if... then...\" in the sense that it is false to claim $A \\\\Rightarrow B$ *only* if $A$ is true when $B$ is false; in all other cases the implication is considered true.  Don\\'t puzzle too much over the meaning of material implication; here it\\'s just meant to be another example of a binary operation.']},\n",
       "  {'cell_type': 'markdown',\n",
       "   'metadata': {'tags': ['problem=1.1', 'points=0.5']},\n",
       "   'source': ['### Problem 1.1 (1/2 point):\\n',\n",
       "    '\\n',\n",
       "    \"> *How many possible binary logical operations are there?*  Don't just report a number; briefly explain your reasoning.\"]},\n",
       "  {'cell_type': 'markdown',\n",
       "   'metadata': {'tags': ['problem=1.2', 'points=0.5']},\n",
       "   'source': ['### Problem 1.2 (1/2 point):\\n',\n",
       "    '\\n',\n",
       "    'An important result in propositional logic is that **all** possible logical operations can be expressed in terms of **NOT**, **AND**, and **OR**; one says this set of operations is *functionally complete*.  In particular, whatever your answer was for Problem 1.1, all of those binary operations can be expressed as some combination of **NOT**, **AND**, and **OR**.  This is important for probability theory, which is built on expressions for probabilities for these three operations on propositions.\\n',\n",
       "    '\\n',\n",
       "    '> *Express **XOR** in terms of **NOT**, **AND**, and **OR** (you may not need all of them).*\\n',\n",
       "    '\\n',\n",
       "    '> Present your result as a truth table similar to this:\\n',\n",
       "    '\\n',\n",
       "    '| $A$ | $B$ |   | OP1 | OP2 | ... |   | **Answer** |\\n',\n",
       "    '|:---:|:---:|---|:---:|:---:|:---:|---|:----------:|\\n',\n",
       "    '| 0   | 0   |   | ?   | ?   |     |   | 0          |\\n',\n",
       "    '| 0   | 1   |   | ?   | ?   |     |   | 1          |\\n',\n",
       "    '| 1   | 0   |   | ?   | ?   |     |   | 1          |\\n',\n",
       "    '| 1   | 1   |   | ?   | ?   |     |   | 0          |\\n',\n",
       "    '\\n',\n",
       "    '> Replace **OP1**, etc., with whatever operations you are composing to construct **XOR** (i.e., showing the ingredients comprising your expression), and replace **Answer** with your final expression (e.g., something like $(A\\\\land B)\\\\lor (\\\\overline{A\\\\lor B}) \\\\land B$, but not exactly that!).\\n',\n",
       "    '\\n',\n",
       "    '[To quickly create nice Markdown markup for the tables above, I used the [Markdown TablesGenerator](http://www.tablesgenerator.com/markdown_tables) that we used in Lab.  Feel free to use it to help with your solutions.]']},\n",
       "  {'cell_type': 'markdown',\n",
       "   'metadata': {'tags': ['problem=1.3', 'points=1']},\n",
       "   'source': ['### Problem 1.3:\\n',\n",
       "    '\\n',\n",
       "    'There are other small sets of functionally complete operations.  In fact, all possible logical operations can be expressed in terms of a **single** binary operator, which may be taken to be either **NAND** (\"*NOT* *AND*\" or \"not both,\" i.e., $\\\\overline{A\\\\land B}$) or **NOR** (\"*NOT* *OR*,\" i.e., $\\\\overline{A\\\\lor B}$, \"neither $A$ nor $B$\"), as defined in the following truth table:\\n',\n",
       "    '\\n',\n",
       "    '| $A$ | $B$ |   | $A$ NAND $B$ | $A$ NOR $B$ |\\n',\n",
       "    '|:---:|:---:|---|:------------:|:-----------:|\\n',\n",
       "    '| 0   | 0   |   | 1            | 1           |\\n',\n",
       "    '| 0   | 1   |   | 1            | 0           |\\n',\n",
       "    '| 1   | 0   |   | 1            | 0           |\\n',\n",
       "    '| 1   | 1   |   | 0            | 0           |\\n',\n",
       "    '\\n',\n",
       "    '> *Pick one of these operators, and express $\\\\overline{A}$, $A\\\\land B$, and $A\\\\lor B$ in terms of it.*  You need only present three expressions (use MathJax LaTeX); no truth tables are necessary.']},\n",
       "  {'cell_type': 'markdown',\n",
       "   'metadata': {'tags': ['problem=1.4', 'points=1']},\n",
       "   'source': ['### Problem 1.4:\\n',\n",
       "    '\\n',\n",
       "    'Digital computers are essentially propositional logic computing devices, built using \"combinational logic gate\" circuit elements that implement basic logic functions (and \"sequential logic\" elements that implement memory).  A key component of a CPU chip in a computer is an *arithmetic logic unit* (ALU) that performs arithmetic and bitwise logic operations on bits and larger groups of binary digits (*nibbles* comprised of 4 bits, *bytes* comprised of 8 bits, and *words* comprised of multiple bytes).  The ALU is built from simple gates that implement desired operations via truth table representations.  For example, the addition of the lowermost bits, $A$ and $B$, of two numbers can be expressed by the following truth table:\\n',\n",
       "    '\\n',\n",
       "    '| $A$ | $B$ |   | Sum | Carry |\\n',\n",
       "    '|:---:|:---:|---|:---:|:-----:|\\n',\n",
       "    '| 0   | 0   |   | 0   | 0     |\\n',\n",
       "    '| 0   | 1   |   | 1   | 0     |\\n',\n",
       "    '| 1   | 0   |   | 1   | 0     |\\n',\n",
       "    '| 1   | 1   |   | 0   | 1     |\\n',\n",
       "    '\\n',\n",
       "    'Here **Sum** denotes the first (lowermost) binary digit of the sum of $A$ and $B$, and **Carry** denotes a carry bit, indicating that $1+1=2$, or 10 in binary (the carry bit will affect the outcome of adding the next highest bits of the numbers being processed by the ALU).  Two logic functions implementing this table comprise a *half adder* (a *full adder* is a trinary operation that handles an additional carry bit input).\\n',\n",
       "    '\\n',\n",
       "    '> *Express the Sum and Carry operations in terms of **NOT**, **AND**, and **OR**.*  Show the intermediate operations in a truth table, along the lines of Problem 1.2.']},\n",
       "  {'cell_type': 'markdown',\n",
       "   'metadata': {},\n",
       "   'source': ['## 2. Base rate fallacy\\n',\n",
       "    '\\n',\n",
       "    'Daniel Kahneman and Amos Tversky did groundbreaking work on the psychology of judgment and decision-making in the 1970s; Kahneman won the 2002 Nobel Memorial Prize in Economic Sciences for this work (Tversky died in 1996 and thus could not share the prize).  They performed numerous ingenious survey-based experiments designed to uncover the heuristics people use to reason amidst uncertainty.  One of their most famous experiments featured the following problem:\\n',\n",
       "    '\\n',\n",
       "    '> A cab was involved in a hit and run accident at night. Two cab companies, the Green and the Blue, operate in the city. The following facts are known:\\n',\n",
       "    '\\n',\n",
       "    '> * 85% of the cabs in the city are Green and 15% are Blue.\\n',\n",
       "    '> * A witness identified the cab as Blue.\\n',\n",
       "    '> * The court tested the reliability of the witness under the same circumstances that existed on the night of the accident and concluded that the witness correctly identified each one of the two colors 80% of the time and failed 20% of the time.\\n',\n",
       "    '\\n',\n",
       "    '> What is the probability that the cab involved in the accident was actually Blue?\\n',\n",
       "    '\\n',\n",
       "    'Kahneman and Tversky found that the typical answer was around 80%.  They used this finding (among many others) to show that humans reason using *heuristics*, mental shortcuts that may give a usable result or decision quickly in some circumstances, but not always the *correct* or *optimal* answer.  For this cab problem, the evidence for use of heuristics came from realizing that the typical answer is *wrong*, i.e., that most people do not reason correctly in this problem.\\n',\n",
       "    '\\n',\n",
       "    \"[If these ideas intrigue you, have a look at Kahneman's 2011 book on this research, [*Thinking, Fast and Slow*](https://us.macmillan.com/thinkingfastandslow/danielkahneman/9780374533557/). The title refers to their idea that the brain has evolved to use two systems for reasoning, a *fast* system that uses imperfect heuristics, and a *slow* system that is capable of careful, sound reasoning. For more brief treatments, see [philosopher Jim Holt's review in the *New York Times*](http://www.nytimes.com/2011/11/27/books/review/thinking-fast-and-slow-by-daniel-kahneman-book-review.html) for a slightly critical overview, or [Wikipedia's summary](https://en.wikipedia.org/wiki/Thinking,_Fast_and_Slow).]\"]},\n",
       "  {'cell_type': 'markdown',\n",
       "   'metadata': {'tags': ['problem=2.1', 'points=1']},\n",
       "   'source': ['### Problem 2.1:\\n',\n",
       "    '\\n',\n",
       "    \"> *Using Bayes's theorem, answer the question posed in the Kahneman/Tversky problem, verifying that the typical answer is incorrect.*\\n\",\n",
       "    '> * Specify the hypothesis space.\\n',\n",
       "    '> * Specify the data proposition.\\n',\n",
       "    '> * Calculate the posterior probabilities for the hypotheses, presenting a table that shows the prior, likelihood, prior$\\\\times$likelihood, and posterior probabilities for the hypotheses.']},\n",
       "  {'cell_type': 'markdown',\n",
       "   'metadata': {'tags': ['problem=2.2', 'points=1']},\n",
       "   'source': ['### Problem 2.2:\\n',\n",
       "    '\\n',\n",
       "    '> Briefly explain what you think the heuristic is that most people used to justify their conclusion.  Criticize it in light of the result of the calculation in Problem 2.1.']},\n",
       "  {'cell_type': 'markdown',\n",
       "   'metadata': {},\n",
       "   'source': ['## More Monty\\n',\n",
       "    '\\n',\n",
       "    \"This problem explores the Monte Hall problem discussed in Lec04; it's also a Markdown/MathJax exercise.\"]},\n",
       "  {'cell_type': 'markdown',\n",
       "   'metadata': {'tags': ['problem=3.1', 'points=1']},\n",
       "   'source': ['### Problem 3.1 — Lazy Monty\\n',\n",
       "    '\\n',\n",
       "    \"One of the contextual assumptions used in the lecture was that, when you have chosen the door with the prize behind it, Monty will open one of the other doors by choosing one of them randomly, with equal probability. Here, consider the lecture setup (where you initially choose door 1, and Monte opens door 3), but with slightly different contextual information, $\\\\mathcal{C}'$, that specifies probabilities $q_2$ and $q_3 = 1-q_2$ that Monty will pick door 2 or door 3 (respectively) when neither hide the prize.  For example, from watching the show, you may have observed that Monty is at the right of the stage, and appears to be lazy: when he could have chosen either door, he tends to favor the one nearest to him (i.e., $q_3 > q_2$).\\n\",\n",
       "    '\\n',\n",
       "    \"> *Recalculate the probability table we computed in the lecture, to calculate posterior probabilities that the prize is behind each of the three doors.  As was done in lecture, assume you've initially chosen door 1, and that Monty opens door 3.*\\n\"]},\n",
       "  {'cell_type': 'markdown',\n",
       "   'metadata': {'tags': ['problem=3.2', 'points=1']},\n",
       "   'source': ['### Problem 3.2 — LTP version\\n',\n",
       "    '\\n',\n",
       "    'Consider again the Monte Hall problem as treated in the lecture. We treated the case where you initially chose door 1, and the datum was the proposition, \"Monty opened door 3\" (which we denoted $D_3$).  It\\'s probably obvious to you that the problem has symmetries: that it doesn\\'t matter which door you initially picked, or which of the other doors Monty opened: it\\'s always in your interest to switch.\\n',\n",
       "    '\\n',\n",
       "    'Here, treat the problem in a more symmetric way.  Keep the assumption that you\\'ve initially chosen door 1.  But suppose you are trying to come up with a *strategy* for the game, before knowing which door Monty opens (but otherwise knowing all the rules, as specified in the lecture).  Let $W$ denote the proposition, \"I will win by switching to the door Monty does not open.\"  \\n',\n",
       "    '\\n',\n",
       "    '> *Compute $P(W|\\\\mathcal{C})$ using the law of total probability (LTP) in the \"extend the conversation\" or \"wishful thinking\" version discussed in Lec03.  Pick a set of exclusive, exhaustive propositions (filling the role of the $B_i$ in Lec03) such that, if you knew one of them were true, you could compute $P(W|B_i,\\\\mathcal{C})$ (use whatever symbol you deem appropriate for $B_i$).  Then use the LTP to account for uncertainty about which of those propositions actually holds.*\\n',\n",
       "    '\\n',\n",
       "    '**Hint:** You should find the same result we found in the specific case treated in class, that the probability for winning if you switch is 2/3.']},\n",
       "  {'cell_type': 'markdown',\n",
       "   'metadata': {},\n",
       "   'source': ['## The beta distribution\\n',\n",
       "    '\\n',\n",
       "    \"This problem explores properties of the beta distribution; it's also a Markdown/MathJax exercise.\\n\",\n",
       "    '\\n',\n",
       "    'Recall the definition of the *beta distribution* PDF for $x\\\\in [0,1]$:\\n',\n",
       "    '$$\\n',\n",
       "    '{\\\\rm Beta}(x|a,b) = \\\\frac{1}{B(a,b)} x^{a-1} (1-x)^{b-1},\\n',\n",
       "    '$$\\n',\n",
       "    'where $B(a,b)$ is the *beta function*,\\n',\n",
       "    '$$\\n',\n",
       "    'B(a,b) \\\\equiv \\\\frac{\\\\Gamma(a) \\\\Gamma(b)}{\\\\Gamma(a+b)} = \\\\int_0^1 dx\\\\, x^{a-1} (1-x)^{b-1}.\\n',\n",
       "    '$$\\n',\n",
       "    'Recall also that the gamma function generalizes factorials to non-integers; in particular, analogous to the result that $n! = n \\\\times (n-1)!$, the gamma function obeys\\n',\n",
       "    '$$\\n',\n",
       "    '\\\\Gamma(z+1) = z\\\\times\\\\Gamma(z).\\n',\n",
       "    '$$']},\n",
       "  {'cell_type': 'markdown',\n",
       "   'metadata': {'tags': ['problem=4.1', 'points=1']},\n",
       "   'source': ['### Problem 4.1:\\n',\n",
       "    '\\n',\n",
       "    '> *Derive the formula given in lecture for the expectation value of $x$, denoted $\\\\Bbb{E}(x)$ or $\\\\langle x\\\\rangle$, in terms of $a$ and $b$, where*\\n',\n",
       "    '$$\\n',\n",
       "    '\\\\Bbb{E}(x) = \\\\int dx\\\\; x \\\\times {\\\\rm Beta}(x|a,b).\\n',\n",
       "    '$$\\n',\n",
       "    '\\n',\n",
       "    'Present your derivation in the Jupyter notebook using MathJax LaTeX notation for the math (make sure to also use text to briefly explain your reasoning). ']},\n",
       "  {'cell_type': 'markdown',\n",
       "   'metadata': {'tags': ['problem=4.2', 'points=1']},\n",
       "   'source': ['### Problem 4.2:\\n',\n",
       "    '\\n',\n",
       "    '> *Derive the formula given in lecture for the mode of the beta distribution, $\\\\hat x$, in terms of $a$ and $b$.  (The mode is the value of $x$ with maximum probability density).*\\n']}],\n",
       " 'metadata': {'celltoolbar': 'Tags',\n",
       "  'kernelspec': {'display_name': 'Python 3',\n",
       "   'language': 'python',\n",
       "   'name': 'python3'},\n",
       "  'language_info': {'codemirror_mode': {'name': 'ipython', 'version': 3},\n",
       "   'file_extension': '.py',\n",
       "   'mimetype': 'text/x-python',\n",
       "   'name': 'python',\n",
       "   'nbconvert_exporter': 'python',\n",
       "   'pygments_lexer': 'ipython3',\n",
       "   'version': '3.7.4'}},\n",
       " 'nbformat': 4,\n",
       " 'nbformat_minor': 1}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{\n",
    " \"cells\": [\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# Assignment 02\\n\",\n",
    "    \"\\n\",\n",
    "    \"**Due:** Thursday, 2020-02-13, 11:59 PM, as a Jupyter notebook submitted via your repo in the course GitHub organization (see the detailed submission instructions in our LabResources repo).  Edit the provided Solution02 notebook with your solutions.  All subproblems are worth 1 point unless otherwise noted (grading will assign fractional points as appropriate).\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 1. Logic problems\\n\",\n",
    "    \"\\n\",\n",
    "    \"We will not be using propositional logic extensively in this course, but it's important to grasp basic logic in order to understand the goals and interpretation of Bayesian inference.\\n\",\n",
    "    \"\\n\",\n",
    "    \"In class we discussed three fundamental logical operations, the unary (operating on a single proposition) **NOT** (denial) operation, and the binary (operating on two propositions) **AND** (conjuction) and **OR** (disjunction) operations.  For propositions $A$ and $B$, with 0 denoting *False* and 1 denoting *True*, the following truth tables describe these operations (I've separated inputs from outputs with an empty column; note that the notebook's table renderer may split headers like \\\"$A\\\\land B$\\\", etc., across a line):\\n\",\n",
    "    \"\\n\",\n",
    "    \"| $A$ |   | $\\\\overline{A}$ |\\n\",\n",
    "    \"|-----|:-:|----------------|\\n\",\n",
    "    \"| 0   |   | 1              |\\n\",\n",
    "    \"| 1   |   | 0              |\\n\",\n",
    "    \"\\n\",\n",
    "    \"| $A$ | $B$ |   | $A \\\\land B$ | $A \\\\lor B$ |\\n\",\n",
    "    \"|:---:|:---:|---|:-----------:|:----------:|\\n\",\n",
    "    \"| 0   | 0   |   | 0           | 0          |\\n\",\n",
    "    \"| 0   | 1   |   | 0           | 1          |\\n\",\n",
    "    \"| 1   | 0   |   | 0           | 1          |\\n\",\n",
    "    \"| 1   | 1   |   | 1           | 1          |\\n\",\n",
    "    \"\\n\",\n",
    "    \"Of course, there are other useful truth-functional operations (unary, binary, and higher order).  For example, **OR** is defined to correspond to *inclusive* \\\"or\\\" in English, but we could also define an *exclusive* \\\"or\\\" operation (\\\"either $A$ or $B$, but not both\\\"), denoted by $\\\\veebar$ and called **XOR**, according to the following truth table:\\n\",\n",
    "    \"\\n\",\n",
    "    \"| $A$ | $B$ |   | $A \\\\veebar B$ |\\n\",\n",
    "    \"|:---:|:---:|---|:-------------:|\\n\",\n",
    "    \"| 0   | 0   |   | 0             |\\n\",\n",
    "    \"| 0   | 1   |   | 1             |\\n\",\n",
    "    \"| 1   | 0   |   | 1             |\\n\",\n",
    "    \"| 1   | 1   |   | 0             |\\n\",\n",
    "    \"\\n\",\n",
    "    \"Similarly, propositional logic uses a *material implication* operator, denoted by $\\\\Rightarrow$, to capture the weakest meaning of statements like \\\"if $A$ is true, then $B$ must be,\\\" with this truth table:\\n\",\n",
    "    \"\\n\",\n",
    "    \"| $A$ | $B$ |   | $A \\\\Rightarrow B$ |\\n\",\n",
    "    \"|:---:|:---:|---|:-----------------:|\\n\",\n",
    "    \"| 0   | 0   |   | 1                 |\\n\",\n",
    "    \"| 0   | 1   |   | 1                 |\\n\",\n",
    "    \"| 1   | 0   |   | 0                 |\\n\",\n",
    "    \"| 1   | 1   |   | 1                 |\\n\",\n",
    "    \"\\n\",\n",
    "    \"$A \\\\Rightarrow B$ captures a weak interpretation of \\\"if... then...\\\" in the sense that it is false to claim $A \\\\Rightarrow B$ *only* if $A$ is true when $B$ is false; in all other cases the implication is considered true.  Don't puzzle too much over the meaning of material implication; here it's just meant to be another example of a binary operation.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {\n",
    "    \"tags\": [\n",
    "     \"problem=1.1\",\n",
    "     \"points=0.5\"\n",
    "    ]\n",
    "   },\n",
    "   \"source\": [\n",
    "    \"### Problem 1.1 (1/2 point):\\n\",\n",
    "    \"\\n\",\n",
    "    \"> *How many possible binary logical operations are there?*  Don't just report a number; briefly explain your reasoning.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {\n",
    "    \"tags\": [\n",
    "     \"problem=1.2\",\n",
    "     \"points=0.5\"\n",
    "    ]\n",
    "   },\n",
    "   \"source\": [\n",
    "    \"### Problem 1.2 (1/2 point):\\n\",\n",
    "    \"\\n\",\n",
    "    \"An important result in propositional logic is that **all** possible logical operations can be expressed in terms of **NOT**, **AND**, and **OR**; one says this set of operations is *functionally complete*.  In particular, whatever your answer was for Problem 1.1, all of those binary operations can be expressed as some combination of **NOT**, **AND**, and **OR**.  This is important for probability theory, which is built on expressions for probabilities for these three operations on propositions.\\n\",\n",
    "    \"\\n\",\n",
    "    \"> *Express **XOR** in terms of **NOT**, **AND**, and **OR** (you may not need all of them).*\\n\",\n",
    "    \"\\n\",\n",
    "    \"> Present your result as a truth table similar to this:\\n\",\n",
    "    \"\\n\",\n",
    "    \"| $A$ | $B$ |   | OP1 | OP2 | ... |   | **Answer** |\\n\",\n",
    "    \"|:---:|:---:|---|:---:|:---:|:---:|---|:----------:|\\n\",\n",
    "    \"| 0   | 0   |   | ?   | ?   |     |   | 0          |\\n\",\n",
    "    \"| 0   | 1   |   | ?   | ?   |     |   | 1          |\\n\",\n",
    "    \"| 1   | 0   |   | ?   | ?   |     |   | 1          |\\n\",\n",
    "    \"| 1   | 1   |   | ?   | ?   |     |   | 0          |\\n\",\n",
    "    \"\\n\",\n",
    "    \"> Replace **OP1**, etc., with whatever operations you are composing to construct **XOR** (i.e., showing the ingredients comprising your expression), and replace **Answer** with your final expression (e.g., something like $(A\\\\land B)\\\\lor (\\\\overline{A\\\\lor B}) \\\\land B$, but not exactly that!).\\n\",\n",
    "    \"\\n\",\n",
    "    \"[To quickly create nice Markdown markup for the tables above, I used the [Markdown TablesGenerator](http://www.tablesgenerator.com/markdown_tables) that we used in Lab.  Feel free to use it to help with your solutions.]\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {\n",
    "    \"tags\": [\n",
    "     \"problem=1.3\",\n",
    "     \"points=1\"\n",
    "    ]\n",
    "   },\n",
    "   \"source\": [\n",
    "    \"### Problem 1.3:\\n\",\n",
    "    \"\\n\",\n",
    "    \"There are other small sets of functionally complete operations.  In fact, all possible logical operations can be expressed in terms of a **single** binary operator, which may be taken to be either **NAND** (\\\"*NOT* *AND*\\\" or \\\"not both,\\\" i.e., $\\\\overline{A\\\\land B}$) or **NOR** (\\\"*NOT* *OR*,\\\" i.e., $\\\\overline{A\\\\lor B}$, \\\"neither $A$ nor $B$\\\"), as defined in the following truth table:\\n\",\n",
    "    \"\\n\",\n",
    "    \"| $A$ | $B$ |   | $A$ NAND $B$ | $A$ NOR $B$ |\\n\",\n",
    "    \"|:---:|:---:|---|:------------:|:-----------:|\\n\",\n",
    "    \"| 0   | 0   |   | 1            | 1           |\\n\",\n",
    "    \"| 0   | 1   |   | 1            | 0           |\\n\",\n",
    "    \"| 1   | 0   |   | 1            | 0           |\\n\",\n",
    "    \"| 1   | 1   |   | 0            | 0           |\\n\",\n",
    "    \"\\n\",\n",
    "    \"> *Pick one of these operators, and express $\\\\overline{A}$, $A\\\\land B$, and $A\\\\lor B$ in terms of it.*  You need only present three expressions (use MathJax LaTeX); no truth tables are necessary.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {\n",
    "    \"tags\": [\n",
    "     \"problem=1.4\",\n",
    "     \"points=1\"\n",
    "    ]\n",
    "   },\n",
    "   \"source\": [\n",
    "    \"### Problem 1.4:\\n\",\n",
    "    \"\\n\",\n",
    "    \"Digital computers are essentially propositional logic computing devices, built using \\\"combinational logic gate\\\" circuit elements that implement basic logic functions (and \\\"sequential logic\\\" elements that implement memory).  A key component of a CPU chip in a computer is an *arithmetic logic unit* (ALU) that performs arithmetic and bitwise logic operations on bits and larger groups of binary digits (*nibbles* comprised of 4 bits, *bytes* comprised of 8 bits, and *words* comprised of multiple bytes).  The ALU is built from simple gates that implement desired operations via truth table representations.  For example, the addition of the lowermost bits, $A$ and $B$, of two numbers can be expressed by the following truth table:\\n\",\n",
    "    \"\\n\",\n",
    "    \"| $A$ | $B$ |   | Sum | Carry |\\n\",\n",
    "    \"|:---:|:---:|---|:---:|:-----:|\\n\",\n",
    "    \"| 0   | 0   |   | 0   | 0     |\\n\",\n",
    "    \"| 0   | 1   |   | 1   | 0     |\\n\",\n",
    "    \"| 1   | 0   |   | 1   | 0     |\\n\",\n",
    "    \"| 1   | 1   |   | 0   | 1     |\\n\",\n",
    "    \"\\n\",\n",
    "    \"Here **Sum** denotes the first (lowermost) binary digit of the sum of $A$ and $B$, and **Carry** denotes a carry bit, indicating that $1+1=2$, or 10 in binary (the carry bit will affect the outcome of adding the next highest bits of the numbers being processed by the ALU).  Two logic functions implementing this table comprise a *half adder* (a *full adder* is a trinary operation that handles an additional carry bit input).\\n\",\n",
    "    \"\\n\",\n",
    "    \"> *Express the Sum and Carry operations in terms of **NOT**, **AND**, and **OR**.*  Show the intermediate operations in a truth table, along the lines of Problem 1.2.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## 2. Base rate fallacy\\n\",\n",
    "    \"\\n\",\n",
    "    \"Daniel Kahneman and Amos Tversky did groundbreaking work on the psychology of judgment and decision-making in the 1970s; Kahneman won the 2002 Nobel Memorial Prize in Economic Sciences for this work (Tversky died in 1996 and thus could not share the prize).  They performed numerous ingenious survey-based experiments designed to uncover the heuristics people use to reason amidst uncertainty.  One of their most famous experiments featured the following problem:\\n\",\n",
    "    \"\\n\",\n",
    "    \"> A cab was involved in a hit and run accident at night. Two cab companies, the Green and the Blue, operate in the city. The following facts are known:\\n\",\n",
    "    \"\\n\",\n",
    "    \"> * 85% of the cabs in the city are Green and 15% are Blue.\\n\",\n",
    "    \"> * A witness identified the cab as Blue.\\n\",\n",
    "    \"> * The court tested the reliability of the witness under the same circumstances that existed on the night of the accident and concluded that the witness correctly identified each one of the two colors 80% of the time and failed 20% of the time.\\n\",\n",
    "    \"\\n\",\n",
    "    \"> What is the probability that the cab involved in the accident was actually Blue?\\n\",\n",
    "    \"\\n\",\n",
    "    \"Kahneman and Tversky found that the typical answer was around 80%.  They used this finding (among many others) to show that humans reason using *heuristics*, mental shortcuts that may give a usable result or decision quickly in some circumstances, but not always the *correct* or *optimal* answer.  For this cab problem, the evidence for use of heuristics came from realizing that the typical answer is *wrong*, i.e., that most people do not reason correctly in this problem.\\n\",\n",
    "    \"\\n\",\n",
    "    \"[If these ideas intrigue you, have a look at Kahneman's 2011 book on this research, [*Thinking, Fast and Slow*](https://us.macmillan.com/thinkingfastandslow/danielkahneman/9780374533557/). The title refers to their idea that the brain has evolved to use two systems for reasoning, a *fast* system that uses imperfect heuristics, and a *slow* system that is capable of careful, sound reasoning. For more brief treatments, see [philosopher Jim Holt's review in the *New York Times*](http://www.nytimes.com/2011/11/27/books/review/thinking-fast-and-slow-by-daniel-kahneman-book-review.html) for a slightly critical overview, or [Wikipedia's summary](https://en.wikipedia.org/wiki/Thinking,_Fast_and_Slow).]\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {\n",
    "    \"tags\": [\n",
    "     \"problem=2.1\",\n",
    "     \"points=1\"\n",
    "    ]\n",
    "   },\n",
    "   \"source\": [\n",
    "    \"### Problem 2.1:\\n\",\n",
    "    \"\\n\",\n",
    "    \"> *Using Bayes's theorem, answer the question posed in the Kahneman/Tversky problem, verifying that the typical answer is incorrect.*\\n\",\n",
    "    \"> * Specify the hypothesis space.\\n\",\n",
    "    \"> * Specify the data proposition.\\n\",\n",
    "    \"> * Calculate the posterior probabilities for the hypotheses, presenting a table that shows the prior, likelihood, prior$\\\\times$likelihood, and posterior probabilities for the hypotheses.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {\n",
    "    \"tags\": [\n",
    "     \"problem=2.2\",\n",
    "     \"points=1\"\n",
    "    ]\n",
    "   },\n",
    "   \"source\": [\n",
    "    \"### Problem 2.2:\\n\",\n",
    "    \"\\n\",\n",
    "    \"> Briefly explain what you think the heuristic is that most people used to justify their conclusion.  Criticize it in light of the result of the calculation in Problem 2.1.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## More Monty\\n\",\n",
    "    \"\\n\",\n",
    "    \"This problem explores the Monte Hall problem discussed in Lec04; it's also a Markdown/MathJax exercise.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {\n",
    "    \"tags\": [\n",
    "     \"problem=3.1\",\n",
    "     \"points=1\"\n",
    "    ]\n",
    "   },\n",
    "   \"source\": [\n",
    "    \"### Problem 3.1 — Lazy Monty\\n\",\n",
    "    \"\\n\",\n",
    "    \"One of the contextual assumptions used in the lecture was that, when you have chosen the door with the prize behind it, Monty will open one of the other doors by choosing one of them randomly, with equal probability. Here, consider the lecture setup (where you initially choose door 1, and Monte opens door 3), but with slightly different contextual information, $\\\\mathcal{C}'$, that specifies probabilities $q_2$ and $q_3 = 1-q_2$ that Monty will pick door 2 or door 3 (respectively) when neither hide the prize.  For example, from watching the show, you may have observed that Monty is at the right of the stage, and appears to be lazy: when he could have chosen either door, he tends to favor the one nearest to him (i.e., $q_3 > q_2$).\\n\",\n",
    "    \"\\n\",\n",
    "    \"> *Recalculate the probability table we computed in the lecture, to calculate posterior probabilities that the prize is behind each of the three doors.  As was done in lecture, assume you've initially chosen door 1, and that Monty opens door 3.*\\n\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {\n",
    "    \"tags\": [\n",
    "     \"problem=3.2\",\n",
    "     \"points=1\"\n",
    "    ]\n",
    "   },\n",
    "   \"source\": [\n",
    "    \"### Problem 3.2 — LTP version\\n\",\n",
    "    \"\\n\",\n",
    "    \"Consider again the Monte Hall problem as treated in the lecture. We treated the case where you initially chose door 1, and the datum was the proposition, \\\"Monty opened door 3\\\" (which we denoted $D_3$).  It's probably obvious to you that the problem has symmetries: that it doesn't matter which door you initially picked, or which of the other doors Monty opened: it's always in your interest to switch.\\n\",\n",
    "    \"\\n\",\n",
    "    \"Here, treat the problem in a more symmetric way.  Keep the assumption that you've initially chosen door 1.  But suppose you are trying to come up with a *strategy* for the game, before knowing which door Monty opens (but otherwise knowing all the rules, as specified in the lecture).  Let $W$ denote the proposition, \\\"I will win by switching to the door Monty does not open.\\\"  \\n\",\n",
    "    \"\\n\",\n",
    "    \"> *Compute $P(W|\\\\mathcal{C})$ using the law of total probability (LTP) in the \\\"extend the conversation\\\" or \\\"wishful thinking\\\" version discussed in Lec03.  Pick a set of exclusive, exhaustive propositions (filling the role of the $B_i$ in Lec03) such that, if you knew one of them were true, you could compute $P(W|B_i,\\\\mathcal{C})$ (use whatever symbol you deem appropriate for $B_i$).  Then use the LTP to account for uncertainty about which of those propositions actually holds.*\\n\",\n",
    "    \"\\n\",\n",
    "    \"**Hint:** You should find the same result we found in the specific case treated in class, that the probability for winning if you switch is 2/3.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"## The beta distribution\\n\",\n",
    "    \"\\n\",\n",
    "    \"This problem explores properties of the beta distribution; it's also a Markdown/MathJax exercise.\\n\",\n",
    "    \"\\n\",\n",
    "    \"Recall the definition of the *beta distribution* PDF for $x\\\\in [0,1]$:\\n\",\n",
    "    \"$$\\n\",\n",
    "    \"{\\\\rm Beta}(x|a,b) = \\\\frac{1}{B(a,b)} x^{a-1} (1-x)^{b-1},\\n\",\n",
    "    \"$$\\n\",\n",
    "    \"where $B(a,b)$ is the *beta function*,\\n\",\n",
    "    \"$$\\n\",\n",
    "    \"B(a,b) \\\\equiv \\\\frac{\\\\Gamma(a) \\\\Gamma(b)}{\\\\Gamma(a+b)} = \\\\int_0^1 dx\\\\, x^{a-1} (1-x)^{b-1}.\\n\",\n",
    "    \"$$\\n\",\n",
    "    \"Recall also that the gamma function generalizes factorials to non-integers; in particular, analogous to the result that $n! = n \\\\times (n-1)!$, the gamma function obeys\\n\",\n",
    "    \"$$\\n\",\n",
    "    \"\\\\Gamma(z+1) = z\\\\times\\\\Gamma(z).\\n\",\n",
    "    \"$$\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {\n",
    "    \"tags\": [\n",
    "     \"problem=4.1\",\n",
    "     \"points=1\"\n",
    "    ]\n",
    "   },\n",
    "   \"source\": [\n",
    "    \"### Problem 4.1:\\n\",\n",
    "    \"\\n\",\n",
    "    \"> *Derive the formula given in lecture for the expectation value of $x$, denoted $\\\\Bbb{E}(x)$ or $\\\\langle x\\\\rangle$, in terms of $a$ and $b$, where*\\n\",\n",
    "    \"$$\\n\",\n",
    "    \"\\\\Bbb{E}(x) = \\\\int dx\\\\; x \\\\times {\\\\rm Beta}(x|a,b).\\n\",\n",
    "    \"$$\\n\",\n",
    "    \"\\n\",\n",
    "    \"Present your derivation in the Jupyter notebook using MathJax LaTeX notation for the math (make sure to also use text to briefly explain your reasoning). \"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {\n",
    "    \"tags\": [\n",
    "     \"problem=4.2\",\n",
    "     \"points=1\"\n",
    "    ]\n",
    "   },\n",
    "   \"source\": [\n",
    "    \"### Problem 4.2:\\n\",\n",
    "    \"\\n\",\n",
    "    \"> *Derive the formula given in lecture for the mode of the beta distribution, $\\\\hat x$, in terms of $a$ and $b$.  (The mode is the value of $x$ with maximum probability density).*\\n\"\n",
    "   ]\n",
    "  }\n",
    " ],\n",
    " \"metadata\": {\n",
    "  \"celltoolbar\": \"Tags\",\n",
    "  \"kernelspec\": {\n",
    "   \"display_name\": \"Python 3\",\n",
    "   \"language\": \"python\",\n",
    "   \"name\": \"python3\"\n",
    "  },\n",
    "  \"language_info\": {\n",
    "   \"codemirror_mode\": {\n",
    "    \"name\": \"ipython\",\n",
    "    \"version\": 3\n",
    "   },\n",
    "   \"file_extension\": \".py\",\n",
    "   \"mimetype\": \"text/x-python\",\n",
    "   \"name\": \"python\",\n",
    "   \"nbconvert_exporter\": \"python\",\n",
    "   \"pygments_lexer\": \"ipython3\",\n",
    "   \"version\": \"3.7.4\"\n",
    "  }\n",
    " },\n",
    " \"nbformat\": 4,\n",
    " \"nbformat_minor\": 1\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
